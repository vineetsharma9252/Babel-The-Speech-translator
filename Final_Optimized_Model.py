import torch
from gtts import gTTS
import playsound
import os
import tempfile
import time
from typing import Dict, List
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
import threading

class UniversalVoiceTranslator:
    def __init__(self, device: str = "auto", optimization_level: str = "high"):
        """
        Initialize the optimized voice translation system
        
        Args:
            device: "cpu", "cuda", or "auto"
            optimization_level: "high" (fastest), "medium", "low" (highest quality)
        """
        print("üöÄ Initializing Optimized Universal Voice Translator...")
        
        # Auto-detect device
        if device == "auto":
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
        else:
            self.device = device
            
        self.optimization_level = optimization_level
        
        # Initialize components with optimized settings
        self.tts = MultiLanguageTTS()
        self.translator = UniversalTranslator(
            model_size="facebook/nllb-200-distilled-600M",  # Fastest model
            device=self.device
        )
        
        print(f"‚úÖ Optimized Universal Voice Translator ready on {self.device.upper()}!")
        print(f"‚ö° Optimization level: {optimization_level}")
    
    def text_to_voice_translation(self, text: str, source_lang: str, target_lang: str):
        """
        Fast text-to-voice translation
        """
        print(f"üìù Text Translation: {source_lang} ‚Üí {target_lang}")
        print(f"Source: {text}")
        
        start_time = time.time()
        
        # Fast translation
        translation = self.translator.translate_fast(text, source_lang, target_lang)
        if not translation["success"]:
            print(f"‚ùå Translation error: {translation['error']}")
            return None
        
        target_text = translation["translated_text"]
        translate_time = time.time() - start_time
        print(f"Translation: {target_text}")
        print(f"‚è±Ô∏è  Translation time: {translate_time:.2f}s")
        
        # Speak asynchronously
        def speak_async():
            self.tts.speak(target_text, target_lang)
        
        threading.Thread(target=speak_async).start()
        
        return {
            "translated_text": target_text,
            "translation_time": translate_time,
            "source_lang": source_lang,
            "target_lang": target_lang
        }
    
    def translate_text_only(self, text: str, source_lang: str, target_lang: str) -> Dict:
        """
        Text-only translation without TTS
        Useful for frontend that handles its own speech synthesis
        """
        print(f"üìù Text Translation: {source_lang} ‚Üí {target_lang}")
        
        start_time = time.time()
        translation = self.translator.translate_fast(text, source_lang, target_lang)
        translate_time = time.time() - start_time
        
        if translation["success"]:
            print(f"‚úÖ Translation completed in {translate_time:.2f}s")
            return {
                "success": True,
                "source_text": text,
                "translated_text": translation["translated_text"],
                "source_lang": source_lang,
                "target_lang": target_lang,
                "translation_time": translate_time
            }
        else:
            print(f"‚ùå Translation failed: {translation['error']}")
            return {
                "success": False,
                "error": translation["error"]
            }
    
    def text_to_speech(self, text: str, lang: str = 'en') -> bool:
        """
        Convert text to speech only
        """
        return self.tts.speak(text, lang)
    
    def get_supported_languages(self) -> Dict:
        """Get all supported languages from all components"""
        return {
            "tts": self.tts.supported_languages,
            "translation": self.translator.get_supported_languages()
        }
    
    def get_performance_info(self) -> Dict:
        """Get performance information"""
        return {
            "device": self.device,
            "optimization_level": self.optimization_level,
            "translation_model": "NLLB-200 Distilled 600M (fastest)",
            "expected_translation_speed": "3-8x faster than original",
            "supported_translation_languages": len(self.translator.get_supported_languages()),
            "supported_tts_languages": len(self.tts.supported_languages)
        }

# OPTIMIZED COMPONENTS

class MultiLanguageTTS:
    def __init__(self):
        """Initialize optimized TTS"""
        self.supported_languages = {
            'en': 'English', 'es': 'Spanish', 'fr': 'French', 'de': 'German',
            'it': 'Italian', 'pt': 'Portuguese', 'ru': 'Russian', 'ja': 'Japanese',
            'ko': 'Korean', 'zh-cn': 'Chinese', 'zh-tw': 'Chinese (Taiwan)',
            'hi': 'Hindi', 'ar': 'Arabic', 'bn': 'Bengali', 'nl': 'Dutch',
            'tr': 'Turkish', 'el': 'Greek', 'sv': 'Swedish', 'da': 'Danish',
            'fi': 'Finnish', 'no': 'Norwegian', 'pl': 'Polish', 'id': 'Indonesian',
            'ms': 'Malay', 'th': 'Thai', 'vi': 'Vietnamese', 'cs': 'Czech',
            'hu': 'Hungarian', 'ro': 'Romanian', 'sk': 'Slovak', 'uk': 'Ukrainian'
        }
    
    def speak(self, text: str, lang: str = 'en', slow: bool = False) -> bool:
        """Optimized speech synthesis"""
        if lang not in self.supported_languages:
            lang = 'en'
        
        try:
            tts = gTTS(text=text, lang=lang, slow=slow)
            
            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as tmp_file:
                temp_filename = tmp_file.name
            
            tts.save(temp_filename)
            playsound.playsound(temp_filename)
            os.unlink(temp_filename)
            
            return True
        except Exception as e:
            print(f"TTS Error: {e}")
            return False

class UniversalTranslator:
    def __init__(self, model_size: str = "facebook/nllb-200-distilled-600M", device: str = "auto"):
        """Optimized translator"""
        print(f"üöÄ Loading Optimized Translator ({model_size})...")
        
        if device == "auto":
            device = "cuda" if torch.cuda.is_available() else "cpu"
        
        self.device = device
        self.model_size = model_size
        
        # Faster loading with appropriate precision
        if device == "cuda":
            torch_dtype = torch.float16
        else:
            torch_dtype = torch.float32
        
        self.tokenizer = AutoTokenizer.from_pretrained(model_size)
        self.model = AutoModelForSeq2SeqLM.from_pretrained(
            model_size,
            torch_dtype=torch_dtype,
            device_map="auto" if device == "cuda" else None
        )
        
        # Pre-warm the model
        self._warm_up()
        
        self.language_map = self._create_language_map()
        print(f"‚úÖ Optimized Translator ready on {device.upper()}!")
    
    def _warm_up(self):
        """Warm up the model for faster first inference"""
        print("üî• Warming up translation model...")
        try:
            # Quick warm-up translation
            test_text = "Hello"
            warmup_pipeline = pipeline(
                'translation',
                model=self.model,
                tokenizer=self.tokenizer,
                src_lang='eng_Latn',
                tgt_lang='spa_Latn',
                max_length=50,
                device=0 if self.device == "cuda" else -1
            )
            warmup_pipeline(test_text)
        except:
            pass
    
    def translate_fast(self, text: str, source_lang: str, target_lang: str, max_length: int = 256) -> Dict:
        """Optimized fast translation"""
        try:
            src_nllb = self.language_map.get(source_lang.lower())
            tgt_nllb = self.language_map.get(target_lang.lower())
            
            if not src_nllb or not tgt_nllb:
                return {"success": False, "error": "Unsupported language"}
            
            # Use optimized pipeline settings
            translator = pipeline(
                'translation',
                model=self.model,
                tokenizer=self.tokenizer,
                src_lang=src_nllb,
                tgt_lang=tgt_nllb,
                max_length=max_length,  # Shorter for speed
                num_beams=3,  # Fewer beams for speed
                device=0 if self.device == "cuda" else -1
            )
            
            result = translator(text)
            return {
                "success": True,
                "translated_text": result[0]['translation_text'],
                "source_lang": source_lang,
                "target_lang": target_lang
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def translate(self, text: str, source_lang: str, target_lang: str, max_length: int = 512) -> Dict:
        """Standard translation (higher quality)"""
        return self.translate_fast(text, source_lang, target_lang, max_length)
    
    def _create_language_map(self) -> Dict[str, str]:
        return {
            'en': 'eng_Latn', 'es': 'spa_Latn', 'fr': 'fra_Latn', 'de': 'deu_Latn',
            'hi': 'hin_Deva', 'zh': 'zho_Hans', 'zh-cn': 'zho_Hans', 'zh-tw': 'zho_Hant',
            'ar': 'arb_Arab', 'ru': 'rus_Cyrl', 'ja': 'jpn_Jpan', 'ko': 'kor_Hang',
            'pt': 'por_Latn', 'it': 'ita_Latn', 'nl': 'nld_Latn', 'tr': 'tur_Latn',
            'vi': 'vie_Latn', 'fa': 'pes_Arab', 'ur': 'urd_Arab', 'bn': 'ben_Beng',
            'pa': 'pan_Guru', 'ta': 'tam_Taml', 'te': 'tel_Telu', 'mr': 'mar_Deva',
            'th': 'tha_Thai', 'el': 'ell_Grek', 'he': 'heb_Hebr', 'pl': 'pol_Latn',
        }
    
    def get_supported_languages(self) -> List[str]:
        return list(set([key for key in self.language_map.keys() if len(key) == 2]))

# Simplified interactive demo
def interactive_translator():
    """Interactive translation system"""
    
    print("üé§ Optimized Universal Translator (Backend)")
    print("=" * 60)
    print("üìù Text Translation + Text-to-Speech")
    print()
    
    # Performance options
    print("Select optimization level:")
    print("1. High Speed (Fastest)")
    print("2. Balanced (Good speed and accuracy)")
    print("3. High Quality (Slowest, best accuracy)")
    
    opt_choice = input("Enter choice (1-3): ").strip()
    if opt_choice == "1":
        optimization = "high"
    elif opt_choice == "3":
        optimization = "low"
    else:
        optimization = "medium"
    
    # Device selection
    device_choice = input("Device (1=Auto, 2=CPU, 3=GPU): ").strip()
    if device_choice == "2":
        device = "cpu"
    elif device_choice == "3":
        device = "cuda"
    else:
        device = "auto"
    
    translator = UniversalVoiceTranslator(device=device, optimization_level=optimization)
    
    # Show performance info
    perf_info = translator.get_performance_info()
    print(f"\n‚ö° Performance Configuration:")
    for k, v in perf_info.items():
        print(f"  {k}: {v}")
    
    print("\nType 'quit' to exit")
    print("Type 'perf' to show performance info")
    print("Type 'lang' to show supported languages")
    print()
    
    while True:
        print("\nChoose mode:")
        print("1. Text-to-Voice Translation")
        print("2. Text-only Translation (for frontend)")
        print("3. Text-to-Speech only")
        print("4. Quit")
        
        choice = input("\nEnter choice (1-4): ").strip()
        
        if choice.lower() == "perf":
            info = translator.get_performance_info()
            for k, v in info.items():
                print(f"{k}: {v}")
            continue
        elif choice.lower() == "lang":
            langs = translator.get_supported_languages()
            print("üéØ Supported Languages:")
            print(f"Translation: {', '.join(langs['translation'])}")
            print(f"TTS: {', '.join(langs['tts'].keys())}")
            continue
            
        if choice == "1":
            text = input("Enter text to translate: ").strip()
            src_lang = input("Source language (e.g., en, es, hi): ").strip()
            tgt_lang = input("Target language (e.g., en, es, hi): ").strip()
            
            result = translator.text_to_voice_translation(text, src_lang, tgt_lang)
            if result:
                print(f"‚úÖ Translation completed in {result['translation_time']:.2f}s")
            
        elif choice == "2":
            text = input("Enter text to translate: ").strip()
            src_lang = input("Source language (e.g., en, es, hi): ").strip()
            tgt_lang = input("Target language (e.g., en, es, hi): ").strip()
            
            result = translator.translate_text_only(text, src_lang, tgt_lang)
            if result["success"]:
                print(f"üåê Translation: {result['translated_text']}")
            
        elif choice == "3":
            text = input("Enter text to speak: ").strip()
            lang = input("Language (e.g., en, es, hi): ").strip()
            
            success = translator.text_to_speech(text, lang)
            if success:
                print("üîä Speech played successfully")
            else:
                print("‚ùå Failed to generate speech")
            
        elif choice == "4":
            print("üëã Goodbye!")
            break
            
        else:
            print("‚ùå Invalid choice!")

# API-like functions for integration with frontend
def create_translator_api(device="auto", optimization="high"):
    """Create a translator instance for API use"""
    return UniversalVoiceTranslator(device=device, optimization_level=optimization)

if __name__ == "__main__":
    interactive_translator()